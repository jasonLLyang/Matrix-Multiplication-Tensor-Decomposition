\documentclass{article}
\usepackage[utf8]{inputenc,hyperref}
\usepackage{amsmath,amsfonts,amssymb,amsthm,verbatim}
\newcommand{\R}{\mathbb{R}}

\title{MM Tensor Decomp progress}
\author{Jason Yang}
\date{Oct 2021 -}

\begin{document}

\maketitle

\subsection*{Notation}
\begin{itemize}
    \item $A\times B$: The outer product of two multidimensional arrays $A,B$, defined as $(A\times B)_{a_0,\dots,a_{p-1},b_0,\dots,b_{q-1}}=A_{a_0,\dots,a_{p-1}}B_{b_0,\dots,b_{q-1}}$ for all indices $a_0,\dots,a_{p-1}$ and $b_0,\dots,b_{q-1}$;
    \item $E(n)_{i,j}$: The $n\times n$ matrix with a 1 at cell $(i,j)$ and 0s everywhere else; if it is clear from context what $n$ is, the abbreviation $E_{i,j}$ may be used;
    \item $\delta_{i,j}=1$ if $i=j$, 0 otherwise (the Kronecker delta);
    \item Commas between indices may be omitted for brevity;
    \item $[N]$ denotes the set $\{0,1,\dots,N-1\}$;
    \item $S_n$ denotes the set of all permutations over $n$ objects;
\end{itemize}

\section{Goal}

For a natural number $n$, the \textit{$<n,n,n>$ matrix multiplication tensor} is defined as
\[\mathcal{M}(n)=\sum_{0\le i,j,k<n} E_{ij}\times E_{jk}\times E_{ki};\]

Thus, $\mathcal{M}(n)_{abcdef}=\delta_{fa}\delta_{bc}\delta_{de}$.

We want to find the minimum $R$ and three lists of matrices $A,B,C$ such that
\[\mathcal{M}(n)=\sum_{r=0}^{R-1}A_r\times B_r\times C_r.\]

$R$ is known as the rank of $\mathcal{M}(n)$, and the list $[(A_r,B_r,C_r)]_{r=0\dots R-1}$ of triplets of matrices satisfying the equation is known as an \textit{$R$-rank decomposition} of $\mathcal{M}(n)$. Note that this equation is equivalent to

\[\forall abcdef,\ \mathcal{M}(n)_{abcdef}=\sum_{r=0}^{R-1}A_{rab}B_{rcd}C_{ref}.\]

The motivation for this problem is that an $R$-rank decomposition of $\mathcal{M}(n)$ can be directly translated into an algorithm for multiplying two $n\times n$ matrices while using only $R$ multiplications between elements of the matrices; we exclude multiplications of elements with fixed scalars. Such an algorithm can then be translated into a $O(N^{\log_n R})$ divide-and-conquer algorithm for multiplying two $N\times N$ matrices for arbitrarily large $N$, which for $R<n^3$ is asymptotically faster than naive matrix multiplication, which has many applications across numerous fields, such as graph algorithms and machine learning.

\section{Transformations of Decompositions}
Given an $R$-rank decomposition $[(A_r,B_r,C_r)]_{r=0\dots R-1}$ of $\mathcal{M}(n)$, we wish to analyze how we can transform it into other valid $R$-rank decompositions.

There are two trivial transformations we can do: one is to permute the triples of the decomposition: $[(A_{\sigma(r)},B_{\sigma(r)},C_{\sigma(r)})]_{r=0\dots R-1}$ for any permutation $\sigma$; the other is to scale elements of each triple with scalars whose product is 1: $[(a_rA_r,b_rB_r,c_rC_r)]_{r=0\dots R-1}$ for any $a_r,b_r,c_r$ such that $a_r b_r c_r=1$ for all $r$.

There is another transformation, called the \textit{trace transformation}, which relies on special properties of $\mathcal{M}(n)$: \[[(\alpha A_r\beta^{-1},\beta B_r\gamma^{-1},\gamma C_r\alpha^{-1})]_{r=0\dots R-1},\] for invertible $n\times n$ matrices $\alpha,\beta,\gamma$. The validity of this transformation can be checked with some algebra.

\subsection{Families of Decompositions}
To find nontrivial decomposition transformations, we can first consider the family of all transformations of the form $[(f_A(A_r),f_B(B_r),f_C(C_r))]_{r=0\dots R-1}$, where $f_A,f_B,f_C:\R^{n\times n}\rightarrow \R^{n\times n}$ are linear transformations over matrices, i.e. each element of the output matrix is a linear combination of all the elements of the input matrix. Thus, we can represent $f_A,f_B,f_C$ with tensors $\alpha,\beta,\gamma$ such that $f_A(A)=\sum_{uv}\alpha_{abuv}A_{uv}$ and likewise for $f_B,\beta$ and $f_C,\gamma$.

Plugging our transformed decomposition into the equation for decompositions of $\mathcal{M}(n)$ and applying some algebraic manipulation gives

\[\forall abcdef,\ \mathcal{M}(n)_{abcdef}=\sum_{r=0}^{R-1}(\sum_{uv}\alpha_{abuv}A_{uv})(\sum_{wx}\beta_{cdwx}B_{rwx})(\sum_{yz}\gamma_{efyz}C_{ryz})\]
\[=\sum_{r=0}^{R-1}\sum_{uvwxyz}\alpha_{abuv}A_{uv}\beta_{cdwx}B_{rwx}\gamma_{efyz}C_{ryz}\]
\[=\sum_{r=0}^{R-1}\sum_{uvwxyz}A_{uv}B_{rwx}C_{ryz}\alpha_{abuv}\beta_{cdwx}\gamma_{efyz}\]
\[=\sum_{uvwxyz}(\sum_{r=0}^{R-1}A_{uv}B_{rwx}C_{ryz})\alpha_{abuv}\beta_{cdwx}\gamma_{efyz}\]
\[=\sum_{uvwxyz}\mathcal{M}(n)_{uvwxyz}\alpha_{abuv}\beta_{cdwx}\gamma_{efyz}\]
\[=\sum_{ijk}\alpha_{abij}\beta_{cdjk}\gamma_{efki}.\]

Thus, any triplet of tensors $\alpha,\beta,\gamma$ satisfying $\mathcal{M}(n)_{abcdef}=\sum_{ijk}\alpha_{abij}\beta_{cdjk}\gamma_{efki}\ \forall abcdef$ is a valid transformation over $R$-rank decompositions.

\subsubsection{Rank 1 (incomplete)}
Suppose we restrict each matrix $\alpha_{ab},\beta_{cd},\gamma_{ef}$ to be rank-1 matrices, i.e. there are tensors $\alpha^0,\alpha^1,\beta^0,\beta^1,\gamma^0,\gamma^1$ such that $\alpha_{abij}=\alpha^0_{abi}\alpha^1_{abj},\beta_{cdjk}=\beta^0_{cdj}\beta^1_{cdk},\gamma_{efki}=\gamma^0_{efk}\gamma^1_{efi}$. Plugging this into the previous equation gives
\[\forall abcdef,\ \mathcal{M}(n)_{abcdef}=\sum_{ijk}\alpha^0_{abi}\alpha^1_{abj}\beta^0_{cdj}\beta^1_{cdk}\gamma^0_{efk}\gamma^1_{efi}\]
\[=\sum_{ijk}\gamma^1_{efi}\alpha^0_{abi}\alpha^1_{abj}\beta^0_{cdj}\beta^1_{cdk}\gamma^0_{efk}\]
\[=(\sum_i\gamma^1_{efi}\alpha^0_{abi})(\sum_j\alpha^1_{abj}\beta^0_{cdj})(\sum_k\beta^1_{cdk}\gamma^0_{efk})\]
\[=(\gamma^1_{ef}\cdot\alpha^0_{ab})(\alpha^1_{ab}\cdot\beta^0_{cd})(\beta^1_{cd}\cdot\gamma^0_{ef})\]
\[=\delta_{fa}\delta_{bc}\delta_{de}.\]

Since this equation must be true for all $abcdef$, we can immediately deduce that $\gamma^1_{ei}\cdot\alpha^0_{ib}\ne 0,\alpha^1_{aj}\cdot\beta^0_{jd}\ne 0$, and $\beta^1_{ck}\cdot\gamma^0_{kf}\ne 0$; otherwise if $\gamma^1_{ei}\cdot\alpha^0_{ib}=0$ for some $i$, then when setting $(abcdef)$ to some $(ijjkki)$ will lead to $(\gamma^1_{ef}\cdot\alpha^0_{ab})(\alpha^1_{ab}\cdot\beta^0_{cd})(\beta^1_{cd}\cdot\gamma^0_{ef})=0\ne \delta_{fa}\delta_{bc}\delta_{de}=1$, and a similar argument applies to the other two inequalities.

We can then further determine that $\gamma^1_{ef}\cdot\alpha^0_{ab}=0$ for all $a\ne b$, since $(\gamma^1_{ef}\cdot\alpha^0_{ab})(\alpha^1_{ab}\cdot\beta^0_{cd})(\beta^1_{cd}\cdot\gamma^0_{ef})=0$ when $(abcdef)$ is set to some $(ajjkkf)$, since then $\alpha^1_{ab}\cdot\beta^0_{cd}$ and $\beta^1_{cd}\cdot\gamma^0_{ef}$ would both be equal to 1. Using similar arguments, $\alpha^1_{ab}\cdot\beta^0_{cd}=0$ for all $c\ne d$ and $\beta^1_{cd}\cdot\gamma^0_{ef}=0$ for all $d\ne e$.

Thus, $[\gamma^1_{ef}\cdot\alpha^0_{ab}]_{f,a}$, $[\alpha^1_{ab}\cdot\beta^0_{cd}]_{b,c}$, and $[\beta^1_{cd}\cdot\gamma^0_{ef}]_{d,e}$ are all diagonal matrices.

\section{Searching for Symmetric Decompositions}
From this point onward we will focus on the case $n=3$. We will use two symmetries of $\mathcal{M}(n)$ and force all the decompositions we search for to have these same symmetries:

\[\mathcal{M}(n)_{a,b,c,d,e,f}=\mathcal{M}(n)_{c,d,e,f,a,b}=\mathcal{M}(n)_{e,f,a,b,c,d}\ \forall a,b,c,d,e,f;\]

\[\mathcal{M}(n)_{a,b,c,d,e,f}=\mathcal{M}(n)_{\sigma(a),\sigma(b),\sigma(c),\sigma(d),\sigma(e),\sigma(f)} \forall \sigma\in S_n.\]

We say two decompositions $[[A_{r,t}]_{t\in[3]}]_{r\in[R]}$ and $[[B_{r,t}]_{t\in[3]}]_{r\in[R]}$ are \textit{equal} if there exists a permutation $\sigma\in S_R$ s.t. $\forall r, [A_{\sigma(r),t}]_{t\in[3]}=[B_{r,t}]_{t\in[3]}$.

We want all decompositions we search for to be equal under all the symmetries described above. Formally, for functions
$h_{\sigma}(A):=[A_{\sigma(r),\sigma(c)}]_{r,c\in[n]}$ and $T_{s,\sigma}([A_t]_{t\in[3]}):=[h_{\sigma}(A_{(t+s)\mod 3})]_{t\in[3]}$, we want decomposition $[[A_{r,t}]_{t\in[3]}]_{r\in[R]}$ to be equal to decomposition $[T_{s,\sigma}([A_{r,t}]_{t\in[3]})]_{r\in[R]}$ for all $s,\sigma$.

\subsection{First attempt}
Consider decompositions of the form $\mathcal{D}=[[P_r]_{t\in[3]}]_{r\in[R_p]}\ ||\ [T_{s,\sigma}([A,B,C])]_{\forall s,\sigma}$ for $P,A,B,C\in\{-1,0,1\}^{3\times 3}$, $P$ satisfying $P=h_\sigma(P)\ \forall\sigma$, and $R_p\le 5$. Note that the second part of the decomposition consists of 18 matrix triples.

We will also define the \textit{error} $e(A,B)$ between two tensors $A,B$ of equal shape to be the number of coordinates $c$ s.t. $A_c\ne B_c$.

By brute force search, the minimum possible $e(\mathcal{M}(3),\mathcal{D})$ is 9. One possible solution is $R_p=0,
A=\begin{bmatrix}
-1 & 0 & 1\\
0 & 0 & 0\\
-1 & 0 & 0\\
\end{bmatrix},
B=\begin{bmatrix}
0 & 0 & 1\\
0 & 0 & 0\\
0 & 0 & 0\\
\end{bmatrix},
C=\begin{bmatrix}
0 & 0 & 0\\
0 & 0 & 0\\
-1 & 0 & 0\\
\end{bmatrix}$.

\section{Symmetry Reduction (old)}
We will use two symmetries of $\mathcal{M}(n)$ to force $A,B,C$ to have these same symmetries, in order to reduce the search space. The first is \textit{cyclic symmetry}, which can be easily verified:

\[\mathcal{M}(n)_{a,b,c,d,e,f}=\mathcal{M}(n)_{c,d,e,f,a,b}=\mathcal{M}(n)_{e,f,a,b,c,d}\ \forall a,b,c,d,e,f.\]

We can force our decomposition of $\mathcal{M}(n)$ to be cyclically symmetric by requiring that for all triplets $(A_r,B_r,C_r)$ in our decomposition, the triplets $(B_r,C_r,A_r)$ and $(C_r,A_r,B_r)$ also appear in the decomposition.

A special case occurs if $(A_r,B_r,C_r)=(\alpha W,\beta W,\gamma W)$ for some matrix $W$ and scalars $\alpha,\beta,\gamma$; in this case $(B_r,C_r,A_r)$ and $(C_r,A_r,B_r)$ do not need to appear as they can be merged with $(A_r,B_r,C_r)$ to yield a single triplet $(3\alpha\beta\gamma W,W,W)$ (note that $(\alpha W,\beta W,\gamma W)$ is equivalent to $(\alpha\beta\gamma W,W,W)$ since the outer product of the matrices in each of the triplets yields the same tensor). We can then adjust the triplet $(3\alpha\beta\gamma W,W,W)$ to $(W',W',W')$ where 
$W'=(3\alpha\beta\gamma)^{\frac{1}{3}}W$, so that the new triplet's matrices are all the same. Thus, every cyclically symmetric decomposition can be written as the form
\[A=W||X||Y||Z,B=W||Y||Z||X,C=W||Z||X||Y\]
where $W,X,Y,Z$ are lists of matrices and $||$ is list concatenation.

Note that Strassen's 7-rank decomposition of $\mathcal{M}(2)$ is cyclically symmetric. Also, Grey Ballard found a cyclically symmetric 23-rank decomposition of $\mathcal{M}(3)$ (\url{http://perso.ens-lyon.fr/bora.ucar/tensors-cse17/ballard-talk.pdf}). Although the rank is the same as the current record, none of the previously discovered 23-rank decompositions were cyclically symmetric.

The second symmetry we will use is \textit{reversal symmetry}:
\[\mathcal{M}(n)_{a,b,c,d,e,f}=\mathcal{M}(n)_{n-1-a,n-1-b,n-1-c,n-1-d,n-1-e,n-1-f}\ \forall a,b,c,d,e,f.\]

We will in fact use an extra-restrictive decomposition of $\mathcal{M}(n)$ when combining both symmetries, namely we will only consider decompositions of the form
\[A=W||X||Y||Z||\overline{X}||\overline{Y}||\overline{Z},B=W||Y||Z||X||\overline{Y}||\overline{Z}||\overline{X},C=W||Z||X||Y||\overline{Z}||\overline{X}||\overline{Y},\]

where $\overline{X}$ denotes the list of matrices $X$ but with each matrix $A$ altered to the matrix $A'=[A_{n-1-i,n-1-j}]_{i,j}$ (i.e. $A$ flipped both horizontally and vertically), and where $W$ satisfies the property $W=\overline{W}$. Strassen's decomposition also satisfies this restrictive form.

\subsection{Progress}
Let $R=|W|$ and $S=|X|=|Y|=|Z|$ represent the length of $W$ and the length of each of $X,Y,Z$ respectively. Our tensor that we want to decompose is $\mathcal{M}(3)$, and our decomposition of interest is
\[A=W||X||Y||Z||\overline{X}||\overline{Y}||\overline{Z},B=W||Y||Z||X||\overline{Y}||\overline{Z}||\overline{X},C=W||Z||X||Y||\overline{Z}||\overline{X}||\overline{Y}.\]
The rank of this decomposition is $R+3S$.

Below is our search progress:
\begin{itemize}
    \item $R\le 5,S\le 2$, each matrix in $A,B,C$ has at most 2 nonzero elements: no decompositions found
\end{itemize}

\end{document}
